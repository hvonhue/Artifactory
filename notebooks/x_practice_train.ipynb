{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2   \n",
    "\n",
    "import sys\n",
    "sys.path.append('../src_jobs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, RichProgressBar\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "from artifact import Saw\n",
    "from data import ArtifactDataset, CachedArtifactDataset\n",
    "from detector import ConvolutionDetector\n",
    "from utilities import parameters_k\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# stop warnings\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # width of window\n",
    "width = 512\n",
    "# convolution_features = [256, 128, 64, 32]\n",
    "# convolution_width = [5, 9, 17, 33]\n",
    "# convolution_dropout = 0.0\n",
    "# transformer_heads = 2\n",
    "# transformer_feedforward = 128\n",
    "# transformer_layers = 2\n",
    "# transformer_dropout = 0\n",
    "# loss = \"mask\"\n",
    "# loss_boost_fp = 0\n",
    "artifact = Saw(min_width=4, max_width=32)\n",
    "# # Optimizer Parameter\n",
    "# # LearningRate Scheduler\n",
    "# # parameters for study\n",
    "batch_size = 128  # 'values': [32, 64, 128]\n",
    "group_name = \"test_setup\"\n",
    "project_name = \"artifactory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionDetector_2.70K_12-01-2024_14:26:14\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = ConvolutionDetector(convolution_features=[32, 16],\n",
    "                            convolution_width=[3, 5],\n",
    "                            convolution_dilation=[1, 1],\n",
    "                            convolution_dropout=0.0,\n",
    "                            convolution_activation=\"sigmoid\")\n",
    "model_name = f\"{model.__class__.__name__}_{parameters_k(model)}_{datetime.now().strftime('%d-%m-%Y_%H:%M:%S')}\"\n",
    "run_name = model_name\n",
    "\n",
    "val_datasets = [\n",
    "    \"australian_electricity_demand_dataset\",\n",
    "    # \"electricity_hourly_dataset\",\n",
    "    # \"electricity_load_diagrams\",\n",
    "    # \"HouseholdPowerConsumption1\",\n",
    "    # \"HouseholdPowerConsumption2\",\n",
    "    # \"london_smart_meters_dataset_without_missing_values\",\n",
    "    # \"solar_10_minutes_dataset\",\n",
    "    # \"wind_farms_minutely_dataset_without_missing_values\",\n",
    "]\n",
    "train_datasets = [\n",
    "    \"australian_electricity_demand_dataset\",\n",
    "    # \"electricity_hourly_dataset\",\n",
    "    # \"electricity_load_diagrams\",\n",
    "    # \"HouseholdPowerConsumption1\",\n",
    "    # \"HouseholdPowerConsumption2\",\n",
    "    # \"london_smart_meters_dataset_without_missing_values\",\n",
    "    # \"solar_10_minutes_dataset\",\n",
    "    # \"wind_farms_minutely_dataset_without_missing_values\",\n",
    "]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series(names: list[str], split: str):\n",
    "    series = list()\n",
    "    counts = list()\n",
    "    for name in names:\n",
    "        with open(f\"../data/processed/{name}_{split}.pickle\", \"rb\") as f:\n",
    "            raw = [a for a in pickle.load(f) if len(a) > width]\n",
    "            series.extend(np.array(a).astype(np.float32) for a in raw)\n",
    "            counts.extend(repeat(1 / len(raw), len(raw)))\n",
    "    counts = np.array(counts)\n",
    "    return series, counts / counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "\n",
    "            # Get to correct shape\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_data, train_weights = load_series(train_datasets, \"TRAIN\")\n",
    "train_dataset = ArtifactDataset(train_data,\n",
    "                                width=width,\n",
    "                                padding=64,\n",
    "                                artifact=artifact,\n",
    "                                weight=train_weights) \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = Path(f\"../data/validation{width}.australian.pkl\")\n",
    "# validation\n",
    "if not val_file.exists():\n",
    "    val_data, val_weights = load_series(val_datasets, \"TEST\")\n",
    "    val_gen = ArtifactDataset(val_data,\n",
    "                              width=width,\n",
    "                              padding=64,\n",
    "                              artifact=artifact,\n",
    "                              weight=val_weights)\n",
    "    val = CachedArtifactDataset.generate(val_gen,\n",
    "                                         n=2048,\n",
    "                                         to=val_file)\n",
    "else:\n",
    "    val = CachedArtifactDataset(file=val_file)\n",
    "val_loader = DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5308, 0.5090, 0.5026,  ..., 0.4493, 0.4551, 0.4724],\n",
       "        [0.3037, 0.3061, 0.3091,  ..., 0.1730, 0.1670, 0.1652],\n",
       "        [0.2437, 0.2393, 0.2332,  ..., 0.1914, 0.1813, 0.1786],\n",
       "        ...,\n",
       "        [0.3147, 0.2959, 0.2694,  ..., 0.4088, 0.4269, 0.4550],\n",
       "        [0.2275, 0.2498, 0.2953,  ..., 0.5478, 0.5325, 0.5079],\n",
       "        [0.4945, 0.4959, 0.4924,  ..., 0.1746, 0.1923, 0.2314]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/12 14:26:16 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "# mlflow.set_tracking_uri(mlflow_uri)\n",
    "mlflow.set_experiment(\"Training_mlFLow_tests\")\n",
    "mlflow.pytorch.autolog()\n",
    "mlflow.start_run(run_name=\"baseline_1\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training_mlFLow_tests'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_experiment(mlflow.active_run().info.experiment_id).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from azureml.core.run import Run\n",
    "# run = Run.get_context()\n",
    "# mlflow_url = run.experiment.workspace.get_mlflow_tracking_uri()\n",
    "# mlf_logger = MLFlowLogger(experiment_name=run.experiment.name, tracking_uri=mlflow_url)\n",
    "# mlf_logger._run_id = run.id\n",
    "# trainer.logger = mlf_logger\n",
    "\n",
    "# run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024/01/12 14:26:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/miniconda/lib/python3.11/site-packages/mlflow/pytorch/_lightning_autolog.py:356: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.4.9 and 2.1.2 and may not succeed with packages outside this range.\"\n",
      "\n",
      "  | Name         | Type           | Params\n",
      "------------------------------------------------\n",
      "0 | convolutions | Sequential     | 2.7 K \n",
      "1 | f1_score     | BinaryF1Score  | 0     \n",
      "2 | accuracy     | BinaryAccuracy | 0     \n",
      "------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1000it [00:36, 27.60it/s, v_num=d322, train_loss_step=0.0335, train_accuracy_step=0.964, train_f1_score_step=0.000, train_loss_epoch=0.0437, train_accuracy_epoch=0.953, train_f1_score_epoch=0.00156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1000it [00:36, 27.59it/s, v_num=d322, train_loss_step=0.0335, train_accuracy_step=0.964, train_f1_score_step=0.000, train_loss_epoch=0.0437, train_accuracy_epoch=0.953, train_f1_score_epoch=0.00156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/12 14:26:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/miniconda/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\"\n",
      "2024/01/12 14:26:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/miniconda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 96.76it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">  Runningstage.validating  </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        validation         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03300036862492561    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       validation_fp       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0033573145046830177   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       validation        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03300036862492561   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      validation_fp      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0033573145046830177  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'validation': 0.03300036862492561, 'validation_fp': 0.0033573145046830177}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize callbacks\n",
    "checkpointcallback = ModelCheckpoint(monitor=\"validation\",\n",
    "                                     mode=\"min\",\n",
    "                                     save_top_k=1)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "# initialize logger\n",
    "logger = MLFlowLogger(\n",
    "                    log_model=\"all\",\n",
    "                    experiment_name=mlflow.get_experiment(mlflow.active_run().info.experiment_id).name,\n",
    "                    tracking_uri=mlflow.get_tracking_uri(),\n",
    "                    run_id=mlflow.active_run().info.run_id\n",
    "    )\n",
    "\n",
    "# initialize trainer\n",
    "trainer = Trainer(logger=logger,\n",
    "                  max_steps=1000,\n",
    "                  val_check_interval=500,\n",
    "                  callbacks=[checkpointcallback,\n",
    "                             lr_monitor, \n",
    "                             # RichProgressBar()\n",
    "                             ])\n",
    "\n",
    "# train\n",
    "trainer.fit(model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "\n",
    "\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241m.\u001b[39mend_run()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
