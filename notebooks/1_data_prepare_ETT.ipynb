{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdb\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "force = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s: np.ndarray) -> list[float]:\n",
    "    n = ((s - s.mean()) / np.std(s)).tolist()\n",
    "    if (n.count('Nan') > 0 or np.std(s) < 0.00001):\n",
    "        print('NaN or std: ', np.std(s))\n",
    "    return n\n",
    "\n",
    "\n",
    "def save(data: np.ndarray,\n",
    "         to: str):\n",
    "    assert isinstance(data, list)\n",
    "    assert isinstance(data[0], list)\n",
    "    assert isinstance(data[0][0], float)\n",
    "    with open(to, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "\n",
    "def split(data: list[np.ndarray],\n",
    "          train: float = .9) -> tuple[list[np.ndarray],\n",
    "                                      list[np.ndarray]]:\n",
    "    \"\"\"Generate a train/test split.\"\"\"\n",
    "    p = int(len(data) * train)\n",
    "    return data[:p], data[p:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity Transformer Temperature (ETT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_h = [\n",
    "    'ETTh1',\n",
    "    'ETTh2'\n",
    "]\n",
    "datasets_m = [\n",
    "    'ETTm1',\n",
    "    'ETTm2'\n",
    "]\n",
    "\n",
    "path = \"../data/raw/ETT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ETT(s: str, path: str) -> pd.DataFrame:\n",
    "    file_name = f\"{path}/{s}.csv\"  \n",
    "    df = pd.read_csv(file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "ett = list()\n",
    "for dataset_name in datasets_h:\n",
    "    train = load_ETT(dataset_name, path)\n",
    "    train.drop(columns=[\"date\", \"OT\"], inplace=True)\n",
    "    train = train.astype(float)\n",
    "    ds = list()\n",
    "    for col in train.columns:\n",
    "        ds.append(normalize(np.array(train[col].tolist())))\n",
    "\n",
    "    ett = ett + ds\n",
    "\n",
    "dataset_train, dataset_test = split(ett)\n",
    "save(dataset_train,\n",
    "    f\"../data/processed/ETTh_TRAIN.pickle\")\n",
    "save(dataset_test,\n",
    "    f\"../data/processed/ETTh_VAL.pickle\")\n",
    "\n",
    "\n",
    "ett = list()\n",
    "for dataset_name in datasets_m:\n",
    "    train = load_ETT(dataset_name, path)\n",
    "    train.drop(columns=[\"date\", \"OT\"], inplace=True)\n",
    "    train = train.astype(float)\n",
    "    ds = list()\n",
    "    for col in train.columns:\n",
    "        ds.append(normalize(np.array(train[col].tolist())))\n",
    "\n",
    "    ett = ett + ds\n",
    "\n",
    "dataset_train, dataset_test = split(ett)\n",
    "save(dataset_train,\n",
    "    f\"../data/processed/ETTm_TRAIN.pickle\")\n",
    "save(dataset_test,\n",
    "    f\"../data/processed/ETTm_VAL.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
