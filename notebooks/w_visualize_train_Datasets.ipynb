{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src_jobs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from itertools import repeat\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from artifact import Saw\n",
    "from detector import WindowTransformerDetector\n",
    "\n",
    "from data import RealisticArtifactDataset, CachedArtifactDataset, TestArtifactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f73f40ae4a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_width = 1024\n",
    "\n",
    "london_test = Path(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/data/validation512.london.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series(names: list[str], split: str):\n",
    "    series = list()\n",
    "    counts = list()\n",
    "    for name in names:\n",
    "        with open(f\"../data/processed/{name}_{split}.pickle\", \"rb\") as f:\n",
    "            raw = [a for a in pickle.load(f) if len(a) > test_width]\n",
    "            series.extend(np.array(a).astype(np.float32) for a in raw)\n",
    "            counts.extend(repeat(1 / len(raw), len(raw)))\n",
    "    counts = np.array(counts)\n",
    "    return series, counts / counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = CachedArtifactDataset(file=london_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "#autheticate\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=credential,\n",
    "    path=\"config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
    "\n",
    "first_detector = WindowTransformerDetector.load_from_checkpoint(\"../models/model.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_full_train\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_full = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=50000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_noLondon\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_6 = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=17000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_mask_5TrainDS\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_5 = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=8000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_mask_4TrainDS\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_4 = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=29000-v1.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_mask_3TrainDS\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_3 = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=12000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_mask_2TrainDS\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_2 = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=7000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_mask_1TrainDS\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_1 = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=1000-v4.ckpt\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "metrics = pd.DataFrame(columns=['detector', 'accuracy', 'precision', 'recall', 'mse'])\n",
    "index = 0\n",
    "\n",
    "preds_1 = list()\n",
    "preds_2 = list()\n",
    "preds_3 = list()\n",
    "preds_4 = list()\n",
    "preds_5 = list()\n",
    "preds_6 = list()\n",
    "preds_full = list()\n",
    "gt = list()\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for sample in val:\n",
    "    example = sample[\"data\"]\n",
    "    stride  = 64\n",
    "    window  = transformer_detector_1.window\n",
    "    length  = len(example)\n",
    "\n",
    "    # add artifact to data\n",
    "    example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "\n",
    "    # store prediction for each window\n",
    "    predictions_1 = torch.zeros(((length - window) // stride + 1, length))\n",
    "    predictions_2 = torch.zeros(((length - window) // stride + 1, length))\n",
    "    predictions_3 = torch.zeros(((length - window) // stride + 1, length))\n",
    "    predictions_4 = torch.zeros(((length - window) // stride + 1, length))\n",
    "    predictions_5 = torch.zeros(((length - window) // stride + 1, length))\n",
    "    predictions_6 = torch.zeros(((length - window) // stride + 1, length))\n",
    "    predictions_full = torch.zeros(((length - window) // stride + 1, length))\n",
    "\n",
    "    # store number of times each mask was predicted\n",
    "    masks = torch.zeros(length)\n",
    "    for i, j in enumerate(range(0, length - window + 1, stride)):\n",
    "        # slice out window\n",
    "        s = example_data[j : j + window]\n",
    "        # make prediction and insert into prediction\n",
    "        predictions_1[i, j : j + window] = transformer_detector_1(s.unsqueeze(0))\n",
    "        predictions_2[i, j : j + window] = transformer_detector_2(s.unsqueeze(0))\n",
    "        predictions_3[i, j : j + window] = transformer_detector_3(s.unsqueeze(0))\n",
    "        predictions_4[i, j : j + window] = transformer_detector_4(s.unsqueeze(0))\n",
    "        predictions_5[i, j : j + window] = transformer_detector_5(s.unsqueeze(0))\n",
    "        predictions_6[i, j : j + window] = transformer_detector_6(s.unsqueeze(0))\n",
    "        predictions_full[i, j : j + window] = transformer_detector_full(s.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        masks[j : j + window] += 1\n",
    "\n",
    "    predictions_1 = predictions_1.sum(axis=0) / masks\n",
    "    preds_1 = preds_1 + predictions_1.tolist()\n",
    "    predictions_1 = np.where(predictions_1.numpy() > threshold, 1, 0)\n",
    "    predictions_2 = predictions_2.sum(axis=0) / masks\n",
    "    preds_2 = preds_2 + predictions_2.tolist()\n",
    "    predictions_2 = np.where(predictions_2.numpy() > threshold, 1, 0)\n",
    "    predictions_3 = predictions_3.sum(axis=0) / masks\n",
    "    preds_3 = preds_3 + predictions_3.tolist()\n",
    "    predictions_3 = np.where(predictions_3.numpy() > threshold, 1, 0)\n",
    "    predictions_4 = predictions_4.sum(axis=0) / masks\n",
    "    preds_4 = preds_4 + predictions_4.tolist()\n",
    "    predictions_4 = np.where(predictions_4.numpy() > threshold, 1, 0)\n",
    "    predictions_5 = predictions_5.sum(axis=0) / masks\n",
    "    preds_5 = preds_5 + predictions_5.tolist()\n",
    "    predictions_5 = np.where(predictions_5.numpy() > threshold, 1, 0)\n",
    "    predictions_6 = predictions_6.sum(axis=0) / masks\n",
    "    preds_6 = preds_6 + predictions_6.tolist()\n",
    "    predictions_6 = np.where(predictions_6.numpy() > threshold, 1, 0)\n",
    "    predictions_full = predictions_full.sum(axis=0) / masks\n",
    "    preds_full = preds_full + predictions_full.tolist()\n",
    "    predictions_full = np.where(predictions_full.numpy() > threshold, 1, 0)\n",
    "    gt = gt + sample[\"mask\"].tolist()\n",
    "\n",
    "    tn_1, fp_1, fn_1, tp_1 = confusion_matrix(sample[\"mask\"], predictions_1, labels=[0, 1]).ravel()\n",
    "    tn_2, fp_2, fn_2, tp_2 = confusion_matrix(sample[\"mask\"], predictions_2, labels=[0, 1]).ravel()\n",
    "    tn_3, fp_3, fn_3, tp_3 = confusion_matrix(sample[\"mask\"], predictions_3, labels=[0, 1]).ravel()\n",
    "    tn_4, fp_4, fn_4, tp_4 = confusion_matrix(sample[\"mask\"], predictions_4, labels=[0, 1]).ravel()\n",
    "    tn_5, fp_5, fn_5, tp_5 = confusion_matrix(sample[\"mask\"], predictions_5, labels=[0, 1]).ravel()\n",
    "    tn_6, fp_6, fn_6, tp_6 = confusion_matrix(sample[\"mask\"], predictions_6, labels=[0, 1]).ravel()\n",
    "    tn_full, fp_full, fn_full, tp_full = confusion_matrix(sample[\"mask\"], predictions_full, labels=[0, 1]).ravel()\n",
    "\n",
    "    new_row_1 = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_1',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_1),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_1),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_1),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_1), \n",
    "        'tn': tn_1,\n",
    "        'fp': fp_1, \n",
    "        'fn': fn_1, \n",
    "        'tp': tp_1\n",
    "    }])\n",
    "\n",
    "    new_row_2 = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_2',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_2),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_2),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_2),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_2),\n",
    "        'tn': tn_2,\n",
    "        'fp': fp_2, \n",
    "        'fn': fn_2, \n",
    "        'tp': tp_2\n",
    "    }])\n",
    "\n",
    "    new_row_3 = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_3',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_3),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_3),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_3),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_3),\n",
    "        'tn': tn_3,\n",
    "        'fp': fp_3, \n",
    "        'fn': fn_3, \n",
    "        'tp': tp_3\n",
    "    }])\n",
    "\n",
    "    new_row_4 = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_4',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_4),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_4),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_4),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_4),\n",
    "        'tn': tn_4,\n",
    "        'fp': fp_4,\n",
    "        'fn': fn_4, \n",
    "        'tp': tp_4\n",
    "    }])\n",
    "\n",
    "    new_row_5 = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_5',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_5),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_5),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_5),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_5),\n",
    "        'tn': tn_5,\n",
    "        'fp': fp_5, \n",
    "        'fn': fn_5, \n",
    "        'tp': tp_5\n",
    "    }])\n",
    "\n",
    "    new_row_6 = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_6',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_6),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_6),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_6),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_6),\n",
    "        'tn': tn_6,\n",
    "        'fp': fp_6,\n",
    "        'fn': fn_6, \n",
    "        'tp': tp_6\n",
    "    }])\n",
    "\n",
    "    new_row_full = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_full',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_full),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_full),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_full),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_full),\n",
    "        'tn': tn_full,\n",
    "        'fp': fp_full,\n",
    "        'fn': fn_full,\n",
    "        'tp': tp_full\n",
    "    }])\n",
    "\n",
    "    metrics = pd.concat([metrics, new_row_1, new_row_2, new_row_3, new_row_4, new_row_5, new_row_6, new_row_full], ignore_index=True)\n",
    "    index = index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_total = metrics.groupby('detector')[['accuracy', 'precision', 'recall', 'mse']].mean()\n",
    "conf_mat_values = metrics.groupby('detector')[['tn', 'fp', 'fn', 'tp']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_values = conf_mat_values.convert_dtypes()\n",
    "conf_mat_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_1)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_1 = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_2)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_2 = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_3)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_3 = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_4)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_4 = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_5)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_5 = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_6)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_6 = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_full)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_full = thresholds[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = np.where(preds_1 > best_thresh_1, 1, 0)\n",
    "predictions_2 = np.where(preds_2 > best_thresh_2, 1, 0)\n",
    "predictions_3 = np.where(preds_3 > best_thresh_3, 1, 0)\n",
    "predictions_4 = np.where(preds_4 > best_thresh_4, 1, 0)\n",
    "predictions_5 = np.where(preds_5 > best_thresh_5, 1, 0)\n",
    "predictions_6 = np.where(preds_6 > best_thresh_6, 1, 0)\n",
    "predictions_full = np.where(preds_full > best_thresh_full, 1, 0)\n",
    "\n",
    "tn_1, fp_1, fn_1, tp_1 = confusion_matrix(gt, predictions_1, labels=[0, 1]).ravel()\n",
    "tn_2, fp_2, fn_2, tp_2 = confusion_matrix(gt, predictions_2, labels=[0, 1]).ravel()\n",
    "tn_3, fp_3, fn_3, tp_3 = confusion_matrix(gt, predictions_3, labels=[0, 1]).ravel()\n",
    "tn_4, fp_4, fn_4, tp_4 = confusion_matrix(gt, predictions_4, labels=[0, 1]).ravel()\n",
    "tn_5, fp_5, fn_5, tp_5 = confusion_matrix(gt, predictions_5, labels=[0, 1]).ravel()\n",
    "tn_6, fp_6, fn_6, tp_6 = confusion_matrix(gt, predictions_6, labels=[0, 1]).ravel()\n",
    "tn_full, fp_full, fn_full, tp_full = confusion_matrix(gt, predictions_full, labels=[0, 1]).ravel()\n",
    "\n",
    "metrics = pd.DataFrame([{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_1',\n",
    "    'threshold': best_thresh_1,\n",
    "    'accuracy': accuracy_score(gt, predictions_1),\n",
    "    'precision': precision_score(gt, predictions_1),\n",
    "    'recall': recall_score(gt, predictions_1),\n",
    "    'mse': mean_squared_error(gt, predictions_1), \n",
    "    'tn': tn_1,\n",
    "    'fp': fp_1, \n",
    "    'fn': fn_1, \n",
    "    'tp': tp_1\n",
    "},\n",
    "{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_2',\n",
    "    'threshold': best_thresh_2,\n",
    "    'accuracy': accuracy_score(gt, predictions_2),\n",
    "    'precision': precision_score(gt, predictions_2),\n",
    "    'recall': recall_score(gt, predictions_2),\n",
    "    'mse': mean_squared_error(gt, predictions_2),\n",
    "    'tn': tn_2,\n",
    "    'fp': fp_2, \n",
    "    'fn': fn_2, \n",
    "    'tp': tp_2\n",
    "},\n",
    "{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_3',\n",
    "    'threshold': best_thresh_3,\n",
    "    'accuracy': accuracy_score(gt, predictions_3),\n",
    "    'precision': precision_score(gt, predictions_3),\n",
    "    'recall': recall_score(gt, predictions_3),\n",
    "    'mse': mean_squared_error(gt, predictions_3),\n",
    "    'tn': tn_3,\n",
    "    'fp': fp_3, \n",
    "    'fn': fn_3, \n",
    "    'tp': tp_3\n",
    "},\n",
    "{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_4',\n",
    "    'threshold': best_thresh_4,\n",
    "    'accuracy': accuracy_score(gt, predictions_4),\n",
    "    'precision': precision_score(gt, predictions_4),\n",
    "    'recall': recall_score(gt, predictions_4),\n",
    "    'mse': mean_squared_error(gt, predictions_4),\n",
    "    'tn': tn_4,\n",
    "    'fp': fp_4,\n",
    "    'fn': fn_4, \n",
    "    'tp': tp_4\n",
    "},\n",
    "{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_5',\n",
    "    'threshold': best_thresh_5,\n",
    "    'accuracy': accuracy_score(gt, predictions_5),\n",
    "    'precision': precision_score(gt, predictions_5),\n",
    "    'recall': recall_score(gt, predictions_5),\n",
    "    'mse': mean_squared_error(gt, predictions_5),\n",
    "    'tn': tn_5,\n",
    "    'fp': fp_5, \n",
    "    'fn': fn_5, \n",
    "    'tp': tp_5\n",
    "},\n",
    "{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_6',\n",
    "    'threshold': best_thresh_6,\n",
    "    'accuracy': accuracy_score(gt, predictions_6),\n",
    "    'precision': precision_score(gt, predictions_6),\n",
    "    'recall': recall_score(gt, predictions_6),\n",
    "    'mse': mean_squared_error(gt, predictions_6),\n",
    "    'tn': tn_6,\n",
    "    'fp': fp_6,\n",
    "    'fn': fn_6, \n",
    "    'tp': tp_6\n",
    "},\n",
    "{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_full',\n",
    "    'threshold': best_thresh_full,\n",
    "    'accuracy': accuracy_score(gt, predictions_full),\n",
    "    'precision': precision_score(gt, predictions_full),\n",
    "    'recall': recall_score(gt, predictions_full),\n",
    "    'mse': mean_squared_error(gt, predictions_full),\n",
    "    'tn': tn_full,\n",
    "    'fp': fp_full,\n",
    "    'fn': fn_full,\n",
    "    'tp': tp_full\n",
    "}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.index=[1,2,3,4,5,6,7]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics[\"precision\"].iloc[:-1].plot(label=\"precision for training on #dataset\", xlabel=\"number of training datasets\", ylabel=\"precision\", title=\"Precision after training for 30000 steps\")\n",
    "plt.plot(7, metrics[\"precision\"].iloc[-1], 'rx', label=\"precision training on all datasets including validationset\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
    "\n",
    "data_asset = ml_client.data.get(\"output_Train_GPU_mask_5TrainDS_noSolar\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_detector_5nS = WindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=17000-v1.ckpt\").cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "metrics = pd.DataFrame(columns=['detector', 'accuracy', 'precision', 'recall', 'mse'])\n",
    "index = 0\n",
    "\n",
    "preds_noSolar = list()\n",
    "gt = list()\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for sample in val:\n",
    "    example = sample[\"data\"]\n",
    "    stride  = 64\n",
    "    window  = transformer_detector_5nS.window\n",
    "    length  = len(example)\n",
    "\n",
    "    # add artifact to data\n",
    "    example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "\n",
    "    # store prediction for each window\n",
    "    predictions_noSolar = torch.zeros(((length - window) // stride + 1, length))\n",
    "\n",
    "    # store number of times each mask was predicted\n",
    "    masks = torch.zeros(length)\n",
    "    for i, j in enumerate(range(0, length - window + 1, stride)):\n",
    "        # slice out window\n",
    "        s = example_data[j : j + window]\n",
    "        # make prediction and insert into prediction\n",
    "        predictions_noSolar[i, j : j + window] = transformer_detector_5nS(s.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        masks[j : j + window] += 1\n",
    "\n",
    "    predictions_noSolar = predictions_noSolar.sum(axis=0) / masks\n",
    "    preds_noSolar = preds_noSolar + predictions_noSolar.tolist()\n",
    "    predictions_noSolar = np.where(predictions_noSolar.numpy() > threshold, 1, 0)\n",
    "    gt = gt + sample[\"mask\"].tolist()\n",
    "\n",
    "    tn_noSolar, fp_noSolar, fn_noSolar, tp_noSolar = confusion_matrix(sample[\"mask\"], predictions_noSolar, labels=[0, 1]).ravel()\n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': 'transformer_detector_5noSolar',\n",
    "        'accuracy': accuracy_score(sample[\"mask\"], predictions_noSolar),\n",
    "        'precision': precision_score(sample[\"mask\"], predictions_noSolar),\n",
    "        'recall': recall_score(sample[\"mask\"], predictions_noSolar),\n",
    "        'mse': mean_squared_error(sample[\"mask\"], predictions_noSolar), \n",
    "        'tn': tn_noSolar,\n",
    "        'fp': fp_noSolar, \n",
    "        'fn': fn_noSolar, \n",
    "        'tp': tp_noSolar\n",
    "    }])\n",
    "\n",
    "    metrics = pd.concat([metrics, new_row], ignore_index=True)\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_noSolar)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_noSolar = thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_noSolar = np.where(preds_noSolar > best_thresh_noSolar, 1, 0)\n",
    "\n",
    "tn_noSolar, fp_noSolar, fn_noSolar, tp_noSolar = confusion_matrix(gt, predictions_noSolar, labels=[0, 1]).ravel()\n",
    "\n",
    "metrics_noSolar = pd.DataFrame([{\n",
    "    'index': index,\n",
    "    'detector': 'transformer_detector_noSolar',\n",
    "    'threshold': best_thresh_noSolar,\n",
    "    'accuracy': accuracy_score(gt, predictions_noSolar),\n",
    "    'precision': precision_score(gt, predictions_noSolar),\n",
    "    'recall': recall_score(gt, predictions_noSolar),\n",
    "    'mse': mean_squared_error(gt, predictions_noSolar), \n",
    "    'tn': tn_noSolar,\n",
    "    'fp': fp_noSolar, \n",
    "    'fn': fn_noSolar, \n",
    "    'tp': tp_noSolar\n",
    "},\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_noSolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_noSolar.to_csv(\"metrics_noSolar.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
