{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdb\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "force = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s: np.ndarray) -> list[float]:\n",
    "    n = ((s - s.mean()) / np.std(s)).tolist()\n",
    "    if (n.count('Nan') > 0 or np.std(s) < 0.00001):\n",
    "        print('NaN or std: ', np.std(s))\n",
    "    return n\n",
    "\n",
    "\n",
    "def save(data: np.ndarray,\n",
    "         to: str):\n",
    "    assert isinstance(data, list)\n",
    "    assert isinstance(data[0], list)\n",
    "    assert isinstance(data[0][0], float)\n",
    "    with open(to, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "\n",
    "def split(data: list[np.ndarray],\n",
    "          train: float = .9) -> tuple[list[np.ndarray],\n",
    "                                      list[np.ndarray]]:\n",
    "    \"\"\"Generate a train/test split.\"\"\"\n",
    "    p = int(len(data) * train)\n",
    "    return data[:p], data[p:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tsdb(s: str):\n",
    "    tsdb.utils.logging.logger.setLevel(logging.ERROR)\n",
    "    raw = tsdb.load_dataset(s)\n",
    "    if s == \"electricity_load_diagrams\":\n",
    "        raw = (raw[\"X\"].select_dtypes(include=[np.number])\n",
    "                       .values.T)\n",
    "        raw = [normalize(s) for s in raw]\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"electricity_load_diagrams\"]:\n",
    "    dataset = download_tsdb(dataset_name)\n",
    "    dataset_train, dataset_test = split(dataset)\n",
    "    save(dataset_train,\n",
    "         f\"../data/processed_2/{dataset_name}_TRAIN.pickle\")\n",
    "    save(dataset_test,\n",
    "         f\"../data/processed_2/{dataset_name}_VAL.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_regression\n",
    "\n",
    "def download_tser(name: str) -> None:\n",
    "    try:\n",
    "        load_regression(name,\n",
    "                        extract_path=\"../data/raw/tser\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "for tser_dataset in [\"HouseholdPowerConsumption1\"]:\n",
    "    download_tser(tser_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def loads_ts(file: str):\n",
    "    lines = [line for line in open(file)\n",
    "             if not (line.startswith(\"#\") or line.startswith(\"@\"))]\n",
    "    series = list()\n",
    "    for line in lines:\n",
    "        channels = line.split('):(')\n",
    "        for channel in channels:\n",
    "            data = re.findall(r\",(\\d+\\.\\d+)\\),\", channel)\n",
    "            data = [float(p) for p in data]\n",
    "            if all(v > 0 for v in data):\n",
    "                series.append(normalize(np.array(data)))\n",
    "    return series\n",
    "\n",
    "for dataset_name in Path(\"../data/raw/tser\").glob(\"**/*.ts\"):\n",
    "    dataset = loads_ts(dataset_name)\n",
    "    save(dataset,\n",
    "         f\"../data/processed_2/{dataset_name.stem}.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_forecasting\n",
    "\n",
    "\n",
    "def download_forecasting(name: str):\n",
    "    data = load_forecasting(name,\n",
    "                            extract_path=\"../data/raw/forecasting\",\n",
    "                            return_metadata=False)\n",
    "    data = data[\"series_value\"].values\n",
    "    data = [s.to_numpy() for s in data]\n",
    "    data = [s for s in data if s.sum() > 0 and len(s) > 1024]\n",
    "    data = [normalize(s) for s in data]\n",
    "    return data\n",
    "\n",
    "\n",
    "for dataset_name in [\"solar_10_minutes_dataset\",\n",
    "                     \"london_smart_meters_dataset_without_missing_values\",\n",
    "                     \"australian_electricity_demand_dataset\",\n",
    "                     \"wind_farms_minutely_dataset_without_missing_values\",\n",
    "                     \"electricity_hourly_dataset\"\n",
    "                     ]:\n",
    "    dataset = download_forecasting(dataset_name)\n",
    "    dataset_train, dataset_test = split(dataset)\n",
    "    save(dataset_train,\n",
    "         f\"../data/processed_2/{dataset_name}_TRAIN.pickle\")\n",
    "    save(dataset_test,\n",
    "         f\"../data/processed_2/{dataset_name}_VAL.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['australian_electricity_demand_dataset',\n",
       " 'electricity_load_diagrams',\n",
       " 'HouseholdPowerConsumption2',\n",
       " 'london_smart_meters_dataset_without_missing_values',\n",
       " 'solar_10_minutes_dataset']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = [\n",
    "   (p.stem\n",
    "     .removesuffix(\"_TRAIN\")\n",
    "     .removesuffix(\"_TEST\")) for p in Path(\"../data/processed_2/\").glob(\"*_TEST.pickle\")\n",
    "]\n",
    "stems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
