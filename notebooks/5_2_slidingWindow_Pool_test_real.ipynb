{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src_jobs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import repeat\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from artifact import Saw_centered\n",
    "from sliding_window_detector import SlidingWindowTransformerDetector, SlidingWindowLinearDetector, FineTunedSlidingWindowDetector\n",
    "\n",
    "from data import CachedArtifactDataset, TestArtifactDataset, CenteredArtifactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f12b017d030>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = pd.read_pickle('/workspaces/AICoE_Ramping_Artefacts/artifactory-master/data/real/normalized_deviation_updated_TEST.pickle') \n",
    "ground_truth = pd.read_csv('/workspaces/AICoE_Ramping_Artefacts/artifactory-master/data/gt_changes_only_relabeled_200K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_width = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "#autheticate\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=credential,\n",
    "    path=\"config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "cnn_dense_635 = SlidingWindowLinearDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=29500.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "cnn_dense_769 = SlidingWindowLinearDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=49000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_587 = SlidingWindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=28000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_671 = SlidingWindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=30000-v2.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_ft = FineTunedSlidingWindowDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/april/epoch=0-step=18500.ckpt\").cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_detector(input: torch.Tensor) -> int:   \n",
    "    input.squeeze(0)\n",
    "    prediction = 0\n",
    "\n",
    "    center = int(input.shape[1]/2)\n",
    "    # flag points with very high increment as artifact\n",
    "    # Calculate increments by subtracting the tensor shifted by one from the original tensor\n",
    "    increments = (input[0][1:] - input[0][:-1]).abs()\n",
    "    mean_increment = torch.mean(increments)\n",
    "    std_increment = torch.std(increments)\n",
    "\n",
    "\n",
    "    if (increments[center-1] > (mean_increment + 2*std_increment)):\n",
    "        prediction = 1\n",
    "    \n",
    "    # # flag highest/lowest point as artifact\n",
    "    # # or better also with mean/std?\n",
    "    # absolute_values = input.abs()\n",
    "    # if input[0][center-1] > absolute_values.sort()[-3]:\n",
    "    #     prediction = 1\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix, roc_curve\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "preds_cnn_1 = list()\n",
    "preds_cnn_2 = list()\n",
    "preds_trans_1 = list()\n",
    "preds_trans_2 = list()\n",
    "preds_trans_ft = list()\n",
    "preds_baseline = list()\n",
    "gt = list()\n",
    "\n",
    "dist = test_width // 2\n",
    "\n",
    "for index, row in ground_truth.iterrows():\n",
    "    example_data = torch.tensor(real_data_df[0][int(row[\"position\"]-dist) : int(row[\"position\"]+dist)])\n",
    "\n",
    "    prediction_cnn_1 = cnn_dense_635(example_data.unsqueeze(0))   \n",
    "    prediction_cnn_2 = cnn_dense_769(example_data.unsqueeze(0))\n",
    "    prediction_trans_1 = transformer_587(example_data.unsqueeze(0))\n",
    "    prediction_trans_2 = transformer_671(example_data.unsqueeze(0))\n",
    "    prediction_trans_ft = transformer_ft(example_data.unsqueeze(0))\n",
    "    prediction_baseline = baseline_detector(example_data.unsqueeze(0))\n",
    "\n",
    "    preds_cnn_1 = preds_cnn_1 + [prediction_cnn_1.numpy()]\n",
    "    preds_cnn_2 = preds_cnn_2 + [prediction_cnn_2.numpy()]\n",
    "    preds_trans_1 = preds_trans_1 + [prediction_trans_1.numpy()]\n",
    "    preds_trans_2 = preds_trans_2 + [prediction_trans_2.numpy()]\n",
    "    preds_trans_ft = preds_trans_ft + [prediction_trans_ft.numpy()]\n",
    "    preds_baseline = preds_baseline + [prediction_baseline]\n",
    "    \n",
    "    gt = gt + [row[\"gt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(preds_trans, label=\"predictions\", c=\"blue\")\n",
    "plt.title(f\"Predictions on synthetic validation set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.pkl', 'rb') as file:\n",
    "    preds_trans = pickle.load(file)\n",
    "\n",
    "with open('gt.pkl', 'rb') as file:\n",
    "    gt = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_cnn_1)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr_cnn1 = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve CNN + Dense 635K Params\")\n",
    "plt.show()\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(gt, preds_cnn_2)\n",
    "# J = precision + recall\n",
    "# ix = np.argmax(J)\n",
    "# best_thresh_pr = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_trans_1)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve CNN + Transformer 587K Params\")\n",
    "plt.show()\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(gt, preds_trans_2)\n",
    "# J = precision + recall\n",
    "# ix = np.argmax(J)\n",
    "# best_thresh_pr = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_trans_ft)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve CNN + Transformer Fine Tuning 587K Params\")\n",
    "plt.show()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_baseline)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve Baseline 0 Params\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_cnn_1 = np.where(preds_cnn_1 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_cnn_1, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_cnn_1 = threshold\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_cnn_2 = np.where(preds_cnn_2 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_cnn_2, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_cnn_2 = threshold\n",
    "\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_trans_1 = np.where(preds_trans_1 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_trans_1, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_trans_1 = threshold\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_trans_2 = np.where(preds_trans_2 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_trans_2, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_trans_2 = threshold\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_trans_ft = np.where(preds_trans_ft > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_trans_ft, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_ft = threshold\n",
    "\n",
    "max_fbeta = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_binary_cnn_1 = [1 if value >= best_threshold_fbeta_cnn_1 else 0 for value in preds_cnn_1]\n",
    "preds_binary_cnn_2 = [1 if value >= best_threshold_fbeta_cnn_2 else 0 for value in preds_cnn_2]\n",
    "preds_binary_trans_1 = [1 if value >= best_threshold_fbeta_trans_1 else 0 for value in preds_trans_1]\n",
    "preds_binary_trans_2 = [1 if value >= best_threshold_fbeta_trans_2 else 0 for value in preds_trans_2]\n",
    "preds_binary_trans_ft = [1 if value >= best_threshold_fbeta_ft else 0 for value in preds_trans_ft]\n",
    "preds_binary_baseline = preds_baseline\n",
    "\n",
    "tn_cnn_1, fp_cnn_1, fn_cnn_1, tp_cnn_1 = confusion_matrix(gt, preds_binary_cnn_1, labels=[0, 1]).ravel()\n",
    "tn_cnn_2, fp_cnn_2, fn_cnn_2, tp_cnn_2 = confusion_matrix(gt, preds_binary_cnn_2, labels=[0, 1]).ravel()\n",
    "tn_trans_1, fp_trans_1, fn_trans_1, tp_trans_1 = confusion_matrix(gt, preds_binary_trans_1, labels=[0, 1]).ravel()\n",
    "tn_trans_2, fp_trans_2, fn_trans_2, tp_trans_2 = confusion_matrix(gt, preds_binary_trans_2, labels=[0, 1]).ravel()\n",
    "tn_trans_ft, fp_trans_ft, fn_trans_ft, tp_trans_ft = confusion_matrix(gt, preds_binary_trans_ft, labels=[0, 1]).ravel()\n",
    "tn_baseline, fp_baseline, fn_baseline, tp_baseline = confusion_matrix(gt, preds_binary_baseline, labels=[0, 1]).ravel()\n",
    "\n",
    "metrics = pd.DataFrame([{\n",
    "    'detector': 'cnn_dense_635K',\n",
    "    'threshold': best_threshold_fbeta_cnn_1,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_cnn_1),\n",
    "    'precision': precision_score(gt, preds_binary_cnn_1),\n",
    "    'recall': recall_score(gt, preds_binary_cnn_1),\n",
    "    'mse': mean_squared_error(gt, preds_binary_cnn_1),\n",
    "    'tn': tn_cnn_1,\n",
    "    'fp': fp_cnn_1, \n",
    "    'fn': fn_cnn_1, \n",
    "    'tp': tp_cnn_1,\n",
    "},\n",
    "# {\n",
    "#     'detector': 'cnn_dense_769K',\n",
    "#     'threshold': best_threshold_fbeta_cnn_2,\n",
    "#     'accuracy': accuracy_score(gt, preds_binary_cnn_2),\n",
    "#     'precision': precision_score(gt, preds_binary_cnn_2),\n",
    "#     'recall': recall_score(gt, preds_binary_cnn_2),\n",
    "#     'mse': mean_squared_error(gt, preds_binary_cnn_2),\n",
    "#     'tn': tn_cnn_2,\n",
    "#     'fp': fp_cnn_2, \n",
    "#     'fn': fn_cnn_2, \n",
    "#     'tp': tp_cnn_2\n",
    "# },\n",
    "{\n",
    "    'detector': 'transformer_587K',\n",
    "    'threshold': best_threshold_fbeta_trans_1,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_trans_1),\n",
    "    'precision': precision_score(gt, preds_binary_trans_1),\n",
    "    'recall': recall_score(gt, preds_binary_trans_1),\n",
    "    'mse': mean_squared_error(gt, preds_binary_trans_1),\n",
    "    'tn': tn_trans_1,\n",
    "    'fp': fp_trans_1, \n",
    "    'fn': fn_trans_1, \n",
    "    'tp': tp_trans_1\n",
    "},\n",
    "# {\n",
    "#     'detector': 'transformer_671K',\n",
    "#     'threshold': best_threshold_fbeta_trans_2,\n",
    "#     'accuracy': accuracy_score(gt, preds_binary_trans_2),\n",
    "#     'precision': precision_score(gt, preds_binary_trans_2),\n",
    "#     'recall': recall_score(gt, preds_binary_trans_2),\n",
    "#     'mse': mean_squared_error(gt, preds_binary_trans_2),\n",
    "#     'tn': tn_trans_2,\n",
    "#     'fp': fp_trans_2, \n",
    "#     'fn': fn_trans_2, \n",
    "#     'tp': tp_trans_2\n",
    "# },    \n",
    "{\n",
    "    'detector': 'ft_transformer_587K',\n",
    "    'threshold': best_threshold_fbeta_ft,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_trans_ft),\n",
    "    'precision': precision_score(gt, preds_binary_trans_ft),\n",
    "    'recall': recall_score(gt, preds_binary_trans_ft),\n",
    "    'mse': mean_squared_error(gt, preds_binary_trans_ft),\n",
    "    'tn': tn_trans_ft,\n",
    "    'fp': fp_trans_ft, \n",
    "    'fn': fn_trans_ft, \n",
    "    'tp': tp_trans_ft\n",
    "},\n",
    "{\n",
    "    'detector': 'baseline',\n",
    "    'threshold': 0.5,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_baseline),\n",
    "    'precision': precision_score(gt, preds_binary_baseline),\n",
    "    'recall': recall_score(gt, preds_binary_baseline),\n",
    "    'mse': mean_squared_error(gt, preds_binary_baseline),\n",
    "    'tn': tn_baseline,\n",
    "    'fp': fp_baseline, \n",
    "    'fn': fn_baseline, \n",
    "    'tp': tp_baseline\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_dense_635K</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.83125</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.837438</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>495</td>\n",
       "      <td>102</td>\n",
       "      <td>33</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer_587K</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.81375</td>\n",
       "      <td>0.600746</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.18625</td>\n",
       "      <td>490</td>\n",
       "      <td>107</td>\n",
       "      <td>42</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ft_transformer_587K</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.82250</td>\n",
       "      <td>0.623482</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.17750</td>\n",
       "      <td>504</td>\n",
       "      <td>93</td>\n",
       "      <td>49</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.26125</td>\n",
       "      <td>590</td>\n",
       "      <td>7</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              detector  threshold  accuracy  precision    recall      mse  \\\n",
       "0       cnn_dense_635K   0.929293   0.83125   0.625000  0.837438  0.16875   \n",
       "1     transformer_587K   0.787879   0.81375   0.600746  0.793103  0.18625   \n",
       "2  ft_transformer_587K   0.777778   0.82250   0.623482  0.758621  0.17750   \n",
       "3             baseline   0.500000   0.73875   0.125000  0.004926  0.26125   \n",
       "\n",
       "    tn   fp   fn   tp  \n",
       "0  495  102   33  170  \n",
       "1  490  107   42  161  \n",
       "2  504   93   49  154  \n",
       "3  590    7  202    1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'index': range(first_artifact_index, last_artifact_index, 15),\n",
    "    'gt': gt,\n",
    "    'predictions': preds_binary\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of samples\n",
    "fp_ind = (df.loc[(df['gt'] == 0) & (df['predictions'] == 1)])[\"index\"]\n",
    "fn_ind = (df.loc[(df['gt'] == 1) & (df['predictions'] == 0)])[\"index\"]\n",
    "tn_ind = (df.loc[(df['gt'] == 0) & (df['predictions'] == 0)])[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in fp_ind[:10]:\n",
    "    example = torch.tensor(real_data_df[0][index-dist : index+dist])\n",
    "    length  = len(example)\n",
    "\n",
    "    prediction_trans = transformer_detector(example.unsqueeze(0))\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(example, label=\"data\", c=\"grey\")\n",
    "    plt.axvline(x=256, c=\"red\", linestyle=\"--\")\n",
    "    plt.title(f\"Predicted positive, but manually labeled negative, sample center {int(index)}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
