{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src_jobs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import repeat\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from artifact import Saw_centered\n",
    "from sliding_window_detector import SlidingWindowTransformerDetector, SlidingWindowLinearDetector, FineTunedSlidingWindowDetector\n",
    "\n",
    "from data import CachedArtifactDataset, TestArtifactDataset, CenteredArtifactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f3db5c4d240>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_width = 512\n",
    "test_file = Path(f\"../data/test_london_slidingWindow_{test_width}.pkl\")\n",
    "test_datasets = [\n",
    "    # \"australian_electricity_demand_dataset\", # accuracy  ~0.95\n",
    "    # \"electricity_hourly_dataset\", # accuracy ~0.976\n",
    "    # \"electricity_load_diagrams\", # ~0.953\n",
    "    # \"HouseholdPowerConsumption1\",\n",
    "    # \"HouseholdPowerConsumption2\",\n",
    "    \"london_smart_meters_dataset_without_missing_values\",\n",
    "    # \"solar_10_minutes_dataset\",\n",
    "    # \"wind_farms_minutely_dataset_without_missing_values\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series(names: list[str], split: str):\n",
    "    series = list()\n",
    "    counts = list()\n",
    "    for name in names:\n",
    "        with open(f\"../data/processed/{name}_{split}.pickle\", \"rb\") as f:\n",
    "            raw = [a for a in pickle.load(f) if len(a) > test_width]\n",
    "            series.extend(np.array(a).astype(np.float32) for a in raw)\n",
    "            counts.extend(repeat(1 / len(raw), len(raw)))\n",
    "    counts = np.array(counts)\n",
    "    return series, counts / counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "if not test_file.exists():\n",
    "    val_data, val_weights = load_series(test_datasets, \"VAL\")\n",
    "    val_gen = CenteredArtifactDataset(\n",
    "        val_data,\n",
    "        width=test_width,\n",
    "        padding=64,\n",
    "        artifact=Saw_centered(),\n",
    "        weight=val_weights,\n",
    "    )\n",
    "    val = CachedArtifactDataset.generate(val_gen,\n",
    "                                         n=2048,\n",
    "                                         to=test_file)\n",
    "else:\n",
    "    val = CachedArtifactDataset(file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "#autheticate\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=credential,\n",
    "    path=\"config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "cnn_dense_635 = SlidingWindowLinearDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=29500.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "cnn_dense_769 = SlidingWindowLinearDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=49000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_587 = SlidingWindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=28000.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_671 = SlidingWindowTransformerDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/epoch=0-step=30000-v2.ckpt\").cpu()\n",
    "\n",
    "data_asset = ml_client.data.get(\"artifactory_output\", version=\"1\")\n",
    "artifact_utils.download_artifact_from_aml_uri(uri=data_asset.path, destination=\"./checkpoints_transformer/\", datastore_operation=ml_client.datastores)\n",
    "transformer_ft = FineTunedSlidingWindowDetector.load_from_checkpoint(\"/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/checkpoints_transformer/april/epoch=0-step=18500.ckpt\").cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_detector(input: torch.Tensor) -> int:   \n",
    "    input.squeeze(0)\n",
    "    prediction = 0\n",
    "\n",
    "    center = int(input.shape[1]/2)\n",
    "    # flag points with very high increment as artifact\n",
    "    # Calculate increments by subtracting the tensor shifted by one from the original tensor\n",
    "    increments = (input[0][1:] - input[0][:-1]).abs()\n",
    "    mean_increment = torch.mean(increments)\n",
    "    print(mean_increment)\n",
    "    std_increment = torch.std(increments)\n",
    "    print(std_increment)\n",
    "    print(increments[center-1])\n",
    "\n",
    "    if increments[center-1] > (mean_increment + 3*std_increment):\n",
    "        prediction = 1\n",
    "        print('yes')\n",
    "    else:\n",
    "        print('no')\n",
    "    \n",
    "    # # flag highest/lowest point as artifact\n",
    "    # # or better also with mean/std?\n",
    "    # absolute_values = input.abs()\n",
    "    # if input[0][center-1] > absolute_values.sort()[-3]:\n",
    "    #     prediction = 1\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_baseline = list()\n",
    "gt = list()\n",
    "\n",
    "for sample in val:\n",
    "    example = sample[\"data\"]\n",
    "    stride  = 64\n",
    "    window  = test_width\n",
    "    length  = len(example)\n",
    "\n",
    "    example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "    prediction_baseline = baseline_detector(example_data.unsqueeze(0))\n",
    "    preds_baseline = preds_baseline + [prediction_baseline]\n",
    "\n",
    "    gt = gt + [sample[\"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "metrics = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'mse'])\n",
    "index = 0\n",
    "\n",
    "preds_cnn_1 = list()\n",
    "preds_cnn_2 = list()\n",
    "preds_trans_1 = list()\n",
    "preds_trans_2 = list()\n",
    "preds_trans_ft = list()\n",
    "preds_baseline = list()\n",
    "gt = list()\n",
    "\n",
    "for sample in val:\n",
    "    example = sample[\"data\"]\n",
    "    stride  = 64\n",
    "    window  = test_width\n",
    "    length  = len(example)\n",
    "\n",
    "    # add artifact to data\n",
    "    example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "\n",
    "    prediction_cnn_1 = cnn_dense_635(example_data.unsqueeze(0))   \n",
    "    prediction_cnn_2 = cnn_dense_769(example_data.unsqueeze(0))\n",
    "    prediction_trans_1 = transformer_587(example_data.unsqueeze(0))\n",
    "    prediction_trans_2 = transformer_671(example_data.unsqueeze(0))\n",
    "    prediction_trans_ft = transformer_ft(example_data.unsqueeze(0))\n",
    "    prediction_baseline = baseline_detector(example_data.unsqueeze(0))\n",
    "\n",
    "    preds_cnn_1 = preds_cnn_1 + [prediction_cnn_1.numpy()]\n",
    "    preds_cnn_2 = preds_cnn_2 + [prediction_cnn_2.numpy()]\n",
    "    preds_trans_1 = preds_trans_1 + [prediction_trans_1.numpy()]\n",
    "    preds_trans_2 = preds_trans_2 + [prediction_trans_2.numpy()]\n",
    "    preds_trans_ft = preds_trans_ft + [prediction_trans_ft.numpy()]\n",
    "    preds_baseline = preds_baseline + [prediction_baseline]\n",
    "\n",
    "    gt = gt + [sample[\"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_cnn_1)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr_cnn1 = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve CNN + Dense 635K Params\")\n",
    "plt.show()\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(gt, preds_cnn_2)\n",
    "# J = precision + recall\n",
    "# ix = np.argmax(J)\n",
    "# best_thresh_pr = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_trans_1)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve CNN + Transformer 587K Params\")\n",
    "plt.show()\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(gt, preds_trans_2)\n",
    "# J = precision + recall\n",
    "# ix = np.argmax(J)\n",
    "# best_thresh_pr = thresholds[ix]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_trans_ft)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve CNN + Transformer Fine Tuning 587K Params\")\n",
    "plt.show()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(gt, preds_baseline)\n",
    "J = precision + recall\n",
    "ix = np.argmax(J)\n",
    "best_thresh_pr = thresholds[ix]\n",
    "\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Precision-Recall curve Baseline 0 Params\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_cnn_1 = np.where(preds_cnn_1 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_cnn_1, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_cnn_1 = threshold\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_cnn_2 = np.where(preds_cnn_2 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_cnn_2, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_cnn_2 = threshold\n",
    "\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_trans_1 = np.where(preds_trans_1 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_trans_1, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_trans_1 = threshold\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_trans_2 = np.where(preds_trans_2 > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_trans_2, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_trans_2 = threshold\n",
    "\n",
    "max_fbeta = 0\n",
    "\n",
    "for threshold in np.linspace(0,  1,  100):\n",
    "    predictions_trans_ft = np.where(preds_trans_ft > threshold, 1, 0)\n",
    "\n",
    "    fbeta = fbeta_score(gt, predictions_trans_ft, average='macro', beta=0.5)\n",
    "\n",
    "    if (fbeta > max_fbeta):\n",
    "        max_fbeta = fbeta\n",
    "        best_threshold_fbeta_ft = threshold\n",
    "\n",
    "max_fbeta = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_binary_cnn_1 = [1 if value >= best_threshold_fbeta_cnn_1 else 0 for value in preds_cnn_1]\n",
    "preds_binary_cnn_2 = [1 if value >= best_threshold_fbeta_cnn_2 else 0 for value in preds_cnn_2]\n",
    "preds_binary_trans_1 = [1 if value >= best_threshold_fbeta_trans_1 else 0 for value in preds_trans_1]\n",
    "preds_binary_trans_2 = [1 if value >= best_threshold_fbeta_trans_2 else 0 for value in preds_trans_2]\n",
    "preds_binary_trans_ft = [1 if value >= best_threshold_fbeta_ft else 0 for value in preds_trans_ft]\n",
    "preds_binary_baseline = preds_baseline\n",
    "\n",
    "tn_cnn_1, fp_cnn_1, fn_cnn_1, tp_cnn_1 = confusion_matrix(gt, preds_binary_cnn_1, labels=[0, 1]).ravel()\n",
    "tn_cnn_2, fp_cnn_2, fn_cnn_2, tp_cnn_2 = confusion_matrix(gt, preds_binary_cnn_2, labels=[0, 1]).ravel()\n",
    "tn_trans_1, fp_trans_1, fn_trans_1, tp_trans_1 = confusion_matrix(gt, preds_binary_trans_1, labels=[0, 1]).ravel()\n",
    "tn_trans_2, fp_trans_2, fn_trans_2, tp_trans_2 = confusion_matrix(gt, preds_binary_trans_2, labels=[0, 1]).ravel()\n",
    "tn_trans_ft, fp_trans_ft, fn_trans_ft, tp_trans_ft = confusion_matrix(gt, preds_binary_trans_ft, labels=[0, 1]).ravel()\n",
    "tn_baseline, fp_baseline, fn_baseline, tp_baseline = confusion_matrix(gt, preds_binary_baseline, labels=[0, 1]).ravel()\n",
    "\n",
    "metrics = pd.DataFrame([{\n",
    "    'detector': 'cnn_dense_635K',\n",
    "    'threshold': best_threshold_fbeta_cnn_1,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_cnn_1),\n",
    "    'precision': precision_score(gt, preds_binary_cnn_1),\n",
    "    'recall': recall_score(gt, preds_binary_cnn_1),\n",
    "    'mse': mean_squared_error(gt, preds_binary_cnn_1),\n",
    "    'tn': tn_cnn_1,\n",
    "    'fp': fp_cnn_1, \n",
    "    'fn': fn_cnn_1, \n",
    "    'tp': tp_cnn_1,\n",
    "},\n",
    "# {\n",
    "#     'detector': 'cnn_dense_769K',\n",
    "#     'threshold': best_threshold_fbeta_cnn_2,\n",
    "#     'accuracy': accuracy_score(gt, preds_binary_cnn_2),\n",
    "#     'precision': precision_score(gt, preds_binary_cnn_2),\n",
    "#     'recall': recall_score(gt, preds_binary_cnn_2),\n",
    "#     'mse': mean_squared_error(gt, preds_binary_cnn_2),\n",
    "#     'tn': tn_cnn_2,\n",
    "#     'fp': fp_cnn_2, \n",
    "#     'fn': fn_cnn_2, \n",
    "#     'tp': tp_cnn_2\n",
    "# },\n",
    "{\n",
    "    'detector': 'transformer_587K',\n",
    "    'threshold': best_threshold_fbeta_trans_1,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_trans_1),\n",
    "    'precision': precision_score(gt, preds_binary_trans_1),\n",
    "    'recall': recall_score(gt, preds_binary_trans_1),\n",
    "    'mse': mean_squared_error(gt, preds_binary_trans_1),\n",
    "    'tn': tn_trans_1,\n",
    "    'fp': fp_trans_1, \n",
    "    'fn': fn_trans_1, \n",
    "    'tp': tp_trans_1\n",
    "},\n",
    "# {\n",
    "#     'detector': 'transformer_671K',\n",
    "#     'threshold': best_threshold_fbeta_trans_2,\n",
    "#     'accuracy': accuracy_score(gt, preds_binary_trans_2),\n",
    "#     'precision': precision_score(gt, preds_binary_trans_2),\n",
    "#     'recall': recall_score(gt, preds_binary_trans_2),\n",
    "#     'mse': mean_squared_error(gt, preds_binary_trans_2),\n",
    "#     'tn': tn_trans_2,\n",
    "#     'fp': fp_trans_2, \n",
    "#     'fn': fn_trans_2, \n",
    "#     'tp': tp_trans_2\n",
    "# },    \n",
    "{\n",
    "    'detector': 'ft_transformer_587K',\n",
    "    'threshold': best_threshold_fbeta_ft,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_trans_ft),\n",
    "    'precision': precision_score(gt, preds_binary_trans_ft),\n",
    "    'recall': recall_score(gt, preds_binary_trans_ft),\n",
    "    'mse': mean_squared_error(gt, preds_binary_trans_ft),\n",
    "    'tn': tn_trans_ft,\n",
    "    'fp': fp_trans_ft, \n",
    "    'fn': fn_trans_ft, \n",
    "    'tp': tp_trans_ft\n",
    "},\n",
    "{\n",
    "    'detector': 'baseline',\n",
    "    'threshold': 0.5,\n",
    "    'accuracy': accuracy_score(gt, preds_binary_baseline),\n",
    "    'precision': precision_score(gt, preds_binary_baseline),\n",
    "    'recall': recall_score(gt, preds_binary_baseline),\n",
    "    'mse': mean_squared_error(gt, preds_binary_baseline),\n",
    "    'tn': tn_baseline,\n",
    "    'fp': fp_baseline, \n",
    "    'fn': fn_baseline, \n",
    "    'tp': tp_baseline\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48818028"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_thresh_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Validation Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5252525252525253"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold_fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Validation Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'index': range(len(val)),\n",
    "    'gt': gt,\n",
    "    'predictions': preds_binary\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar plot\n",
    "plt.hist(preds_trans, bins=10)\n",
    "\n",
    "# Customize the plot (optional)\n",
    "plt.title(\"Predictions on synthetic validation set\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of samples\n",
    "fp_ind = (df.loc[(df['gt'] == 0) & (df['predictions'] == 1)])[\"index\"]\n",
    "fn_ind = (df.loc[(df['gt'] == 1) & (df['predictions'] == 0)])[\"index\"]\n",
    "tn_ind = (df.loc[(df['gt'] == 0) & (df['predictions'] == 0)])[\"index\"]\n",
    "tp_ind = (df.loc[(df['gt'] == 1) & (df['predictions'] == 1)])[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "for index in tp_ind[10:20]:\n",
    "    sample = val[int(index)]\n",
    "    label = sample[\"label\"]\n",
    "    example = torch.tensor(sample[\"data\"] + sample[\"artifact\"])\n",
    "\n",
    "    length  = len(example)\n",
    "\n",
    "    prediction_trans = transformer_detector(example.unsqueeze(0))\n",
    "\n",
    "    plt.figure(figsize=(10, 6.666))\n",
    "    plt.plot(example, label=\"data\", c=\"blue\", linewidth=3.0)\n",
    "    plt.axvline(x=256, c=\"red\", linestyle=\"--\", linewidth=3.0, dashes=(4,4), label=\"position of artifact\")\n",
    "    # changing the fontsize of yticks\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.xlabel(\"#Time steps [a.u.]\", fontsize=20)\n",
    "    plt.ylabel(\"Power [a.u.]\", fontsize=20)\n",
    "    # to set the font size of the legend \n",
    "    # plt.title(f\"Label: {label}, prediction: {prediction_trans}, sample number {int(index)}\")\n",
    "    #plt.title(f\"Sliding Window detector, artifact in the middle: {label}\")\n",
    "    # to set the font size of the legend \n",
    "    matplotlib.rcParams['legend.fontsize'] = 15\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
