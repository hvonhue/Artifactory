{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study about loss function with penalty term for a high number of false positives\n",
    "\n",
    "This notebook recreates the results shown in the short ablation study about the epsilon parameter of the loss function.\n",
    "\n",
    "We try 6 differen values for epsilon: 0, 0.1, 0.2, 0.3, 0.4, 0.5\n",
    "\n",
    "To run this notebook in the codespace, choose the base kernel (Python 3.10.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../artitect/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from itertools import repeat\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from artifact import Saw\n",
    "from sliding_window_detector import SlidingWindowTransformerDetector, ConvolutionalSlidingWindowDetector, SlidingWindowLinearDetector\n",
    "from mask_detector import WindowLinearDetector, WindowTransformerDetector, ConvolutionDetector\n",
    "\n",
    "from data import RealisticArtifactDataset, CachedArtifactDataset, TestArtifactDataset, CenteredArtifactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_width = 512\n",
    "\n",
    "test_path = Path(\"../data/test_files/test_label_CinCECGTorso512.pkl\")\n",
    "test = CachedArtifactDataset(file=test_path)\n",
    "\n",
    "val_path = Path(\"../data/val_files/val_SW_noCiECGT512.pkl\")\n",
    "val = CachedArtifactDataset(file=val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'act_fct' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fct'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "paths_SW = \"../models/ablationFP/SW_FCNTrans_fpbosst_0.ckpt\" # SW FCN\n",
    "adaFCNTrans_0 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/ablationFP/SW_FCNTrans_fpboost_01.ckpt\" # SW FCN\n",
    "adaFCNTrans_0_1 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/ablationFP/SW_FCNTrans_fpboost_02.ckpt\" # SW FCN\n",
    "adaFCNTrans_0_2 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/ablationFP/SW_FCNTrans_fpboost_03.ckpt\" # SW FCN\n",
    "adaFCNTrans_0_3 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/ablationFP/SW_FCNTrans_fpboost_04.ckpt\" # SW FCN\n",
    "adaFCNTrans_0_4 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/ablationFP/SW_FCNTrans_fpboost_05.ckpt\" # SW FCN\n",
    "adaFCNTrans_0_5 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "SW_detectors = [adaFCNTrans_0.eval(), adaFCNTrans_0_1.eval(), adaFCNTrans_0_2.eval(), adaFCNTrans_0_3.eval(), adaFCNTrans_0_4.eval(), adaFCNTrans_0_5.eval()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_detector(input: torch.Tensor) -> int:   \n",
    "    input.squeeze(0)\n",
    "    prediction = 0\n",
    "\n",
    "    center = int(input.shape[1]/2)\n",
    "    # flag points with very high increment as artifact\n",
    "    # Calculate increments by subtracting the tensor shifted by one from the original tensor\n",
    "    increments = (input[0][1:] - input[0][:-1]).abs()\n",
    "    mean_increment = torch.mean(increments)\n",
    "    std_increment = torch.std(increments)\n",
    "\n",
    "    if increments[center-1] > (mean_increment + 3*std_increment):\n",
    "        prediction = 1\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Validation set for threshold calculation with fbeta score\n",
    "\n",
    "In case you do not want to perform the threshold search, skip to the cell that contains the hard coded thresholds and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/torch/nn/modules/conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "all_predictions_valSet = pd.DataFrame(columns=['Detector_id', 'predictions'])\n",
    "index = 0\n",
    "gt = list()\n",
    "\n",
    "for detector in SW_detectors:\n",
    "\n",
    "    preds = list()\n",
    "\n",
    "    for sample in val:\n",
    "        example = sample[\"data\"]\n",
    "        window  = detector.window\n",
    "        length  = len(example)\n",
    "\n",
    "        # add artifact to data\n",
    "        example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "\n",
    "        # set detector to evaluation mode\n",
    "        detector.eval()\n",
    "        # make prediction and insert into prediction\n",
    "        prediction = detector(example_data.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        preds = preds + [prediction.numpy()]\n",
    "\n",
    "        if index == 0 :\n",
    "            gt = gt + [sample[\"label\"]]\n",
    "    \n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'Detector_id': index +1,\n",
    "        'predictions': preds\n",
    "    }])\n",
    "\n",
    "    all_predictions_valSet = pd.concat([all_predictions_valSet,new_row])\n",
    "    index = index +1\n",
    "    print(len(all_predictions_valSet))\n",
    "\n",
    "all_predictions_valSet = pd.concat([\n",
    "    all_predictions_valSet,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': 0,\n",
    "        'predictions': gt\n",
    "    }])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "gt = all_predictions_valSet.iloc[-1][\"predictions\"]\n",
    "metrics = pd.DataFrame()\n",
    "for index, row in all_predictions_valSet.iterrows():\n",
    "\n",
    "    max_fbeta = 0\n",
    "\n",
    "    for threshold in np.linspace(0,  1,  100):\n",
    "        predictions = np.where(np.array(row['predictions']) > threshold, 1, 0)\n",
    "\n",
    "        fbeta = fbeta_score(gt, predictions, average='macro', beta=0.5)\n",
    "\n",
    "        if (fbeta > max_fbeta):\n",
    "            max_fbeta = fbeta\n",
    "            best_threshold_fbeta = threshold\n",
    "\n",
    "    predictions = np.where(np.array(row['predictions']) > best_threshold_fbeta, 1, 0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(gt, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "    metric = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': f\"detector{row['Detector_id']}\",\n",
    "        'threshold': best_threshold_fbeta,\n",
    "        'fbeta_score': fbeta_score(gt, predictions, beta=0.5),\n",
    "        'accuracy': accuracy_score(gt, predictions),\n",
    "        'precision': precision_score(gt, predictions),\n",
    "        'recall': recall_score(gt, predictions),\n",
    "        'mse': mean_squared_error(gt, predictions), \n",
    "        'tn': tn,\n",
    "        'fp': fp, \n",
    "        'fn': fn, \n",
    "        'tp': tp\n",
    "    }])\n",
    "\n",
    "    metrics = pd.concat([metrics, metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = list(metrics[\"threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0] + thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with this cell for skipping the threshold calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 0.464, 0.363, 0.252, 0.262, 0.484, 0.212, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/torch/nn/modules/conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "all_predictions = pd.DataFrame(columns=['Detector_id', 'predictions'])\n",
    "index = 1\n",
    "gt = list()\n",
    "preds_baseline = list()\n",
    "\n",
    "for sample in test:\n",
    "    example = sample[\"data\"]\n",
    "    stride  = 64\n",
    "    window  = test_width\n",
    "    length  = len(example)\n",
    "\n",
    "    example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "    prediction_baseline = baseline_detector(example_data.unsqueeze(0))\n",
    "    preds_baseline = preds_baseline + [prediction_baseline]\n",
    "\n",
    "    gt = gt + [sample[\"label\"]]\n",
    "\n",
    "all_predictions = pd.concat([\n",
    "    all_predictions,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': index,\n",
    "        'predictions': preds_baseline\n",
    "    }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "index = 2\n",
    "\n",
    "for detector in SW_detectors:\n",
    "\n",
    "    preds = list()\n",
    "\n",
    "    for sample in test:\n",
    "        example = sample[\"data\"]\n",
    "        window  = detector.window\n",
    "        length  = len(example)\n",
    "\n",
    "        # add artifact to data\n",
    "        example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "\n",
    "        # set detector to evaluation mode\n",
    "        detector.eval()\n",
    "        # make prediction and insert into prediction\n",
    "        prediction = detector(example_data.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        preds = preds + [prediction.numpy()]\n",
    "    \n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'Detector_id': index,\n",
    "        'predictions': preds\n",
    "    }])\n",
    "\n",
    "    all_predictions = pd.concat([all_predictions,new_row], ignore_index=True)\n",
    "    index = index +1\n",
    "    print(len(all_predictions))\n",
    "\n",
    "\n",
    "all_predictions = pd.concat([\n",
    "    all_predictions,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': 0,\n",
    "        'predictions': gt\n",
    "    }])\n",
    "    ], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "gt = all_predictions.iloc[-1][\"predictions\"]\n",
    "metrics = pd.DataFrame()\n",
    "for index, row in all_predictions.iterrows():\n",
    "\n",
    "    predictions = np.where(np.array(row['predictions']) > thresholds[index], 1, 0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(gt, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "    metric = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': f\"detector{row['Detector_id']}\",\n",
    "        'threshold': thresholds[index],\n",
    "        'fbeta_score': fbeta_score(gt, predictions, beta=0.5),\n",
    "        'accuracy': accuracy_score(gt, predictions),\n",
    "        'precision': precision_score(gt, predictions),\n",
    "        'recall': recall_score(gt, predictions),\n",
    "        'mse': mean_squared_error(gt, predictions), \n",
    "        'tn': tn,\n",
    "        'fp': fp, \n",
    "        'fn': fn, \n",
    "        'tp': tp\n",
    "    }])\n",
    "\n",
    "    metrics = pd.concat([metrics, metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>detector</th>\n",
       "      <th>threshold</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>detector1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.974131</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>0.979675</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>1016</td>\n",
       "      <td>20</td>\n",
       "      <td>48</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>detector2</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.985772</td>\n",
       "      <td>0.976074</td>\n",
       "      <td>0.992835</td>\n",
       "      <td>0.958498</td>\n",
       "      <td>0.023926</td>\n",
       "      <td>1029</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>detector3</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.980431</td>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.982983</td>\n",
       "      <td>0.970356</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>1019</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>detector4</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.993512</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968379</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1036</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>detector5</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.983157</td>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.957510</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>1026</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>detector6</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.983157</td>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.957510</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>1026</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>detector7</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.980509</td>\n",
       "      <td>0.978516</td>\n",
       "      <td>0.982072</td>\n",
       "      <td>0.974308</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>1018</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>detector0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   detector  threshold  fbeta_score  accuracy  precision    recall  \\\n",
       "0      0  detector1      0.000     0.974131  0.966797   0.979675  0.952569   \n",
       "0      1  detector2      0.464     0.985772  0.976074   0.992835  0.958498   \n",
       "0      2  detector3      0.363     0.980431  0.977051   0.982983  0.970356   \n",
       "0      3  detector4      0.252     0.993512  0.984375   1.000000  0.968379   \n",
       "0      4  detector5      0.262     0.983157  0.974121   0.989785  0.957510   \n",
       "0      5  detector6      0.484     0.983157  0.974121   0.989785  0.957510   \n",
       "0      6  detector7      0.212     0.980509  0.978516   0.982072  0.974308   \n",
       "0      7  detector0      0.000     1.000000  1.000000   1.000000  1.000000   \n",
       "\n",
       "        mse    tn  fp  fn    tp  \n",
       "0  0.033203  1016  20  48   964  \n",
       "0  0.023926  1029   7  42   970  \n",
       "0  0.022949  1019  17  30   982  \n",
       "0  0.015625  1036   0  32   980  \n",
       "0  0.025879  1026  10  43   969  \n",
       "0  0.025879  1026  10  43   969  \n",
       "0  0.021484  1018  18  26   986  \n",
       "0  0.000000  1036   0   0  1012  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the manually labeled test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_width =512\n",
    "\n",
    "real_data_df = pd.read_pickle('../data/real/normalized_deviation_updated_TEST.pickle') \n",
    "ground_truth = pd.read_csv('../data/real/gt_changes_only_relabeled_200K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/torch/nn/modules/conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "all_predictions_real = pd.DataFrame(columns=['Detector_id', 'predictions'])\n",
    "dist = test_width // 2\n",
    "\n",
    "index = 1\n",
    "gt = list()\n",
    "preds_baseline = list()\n",
    "\n",
    "for index, row in ground_truth[:494].iterrows():\n",
    "    example_data = torch.tensor(real_data_df[0][int(row[\"position\"]-dist) : int(row[\"position\"]+dist)])\n",
    "    \n",
    "    prediction_baseline = baseline_detector(example_data.unsqueeze(0))\n",
    "    preds_baseline = preds_baseline + [prediction_baseline]\n",
    "\n",
    "    gt = gt + [row[\"gt\"]]\n",
    "\n",
    "all_predictions_real = pd.concat([\n",
    "    all_predictions_real,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': index,\n",
    "        'predictions': preds_baseline\n",
    "    }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "index = 2\n",
    "\n",
    "for detector in SW_detectors:\n",
    "\n",
    "    preds = list()\n",
    "\n",
    "    for index, row in ground_truth[:494].iterrows():\n",
    "        example_data = torch.tensor(real_data_df[0][int(row[\"position\"]-dist) : int(row[\"position\"]+dist)])\n",
    "        # make prediction and insert into prediction\n",
    "        prediction = detector(example_data.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        preds = preds + [prediction.numpy()] \n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'Detector_id': index ,\n",
    "        'predictions': preds\n",
    "    }])\n",
    "\n",
    "    all_predictions_real = pd.concat([all_predictions_real,new_row], ignore_index=True)\n",
    "    index = index +1\n",
    "    print(len(all_predictions_real))\n",
    "\n",
    "\n",
    "all_predictions_real = pd.concat([\n",
    "    all_predictions_real,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': 0,\n",
    "        'predictions': gt\n",
    "    }])\n",
    "    ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_real.drop(all_predictions_real.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "gt_real = ground_truth[:494][\"gt\"]\n",
    "metrics_real = pd.DataFrame()\n",
    "\n",
    "for index, row in all_predictions_real.iterrows():\n",
    "\n",
    "    predictions = np.where(np.array(row['predictions']) > thresholds[index], 1, 0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(gt_real, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "    metric = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': f\"Detector{row['Detector_id']}\",\n",
    "        'threshold': thresholds[index],\n",
    "        'fbeta_score': fbeta_score(gt_real, predictions, beta=0.5),\n",
    "        'accuracy': accuracy_score(gt_real, predictions),\n",
    "        'precision': precision_score(gt_real, predictions),\n",
    "        'recall': recall_score(gt_real, predictions),\n",
    "        'mse': mean_squared_error(gt_real, predictions), \n",
    "        'tn': tn,\n",
    "        'fp': fp, \n",
    "        'fn': fn, \n",
    "        'tp': tp, \n",
    "    }])\n",
    "\n",
    "    metrics_real = pd.concat([metrics_real, metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>detector</th>\n",
       "      <th>threshold</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408907</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.679443</td>\n",
       "      <td>0.718623</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>0.281377</td>\n",
       "      <td>277</td>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.708419</td>\n",
       "      <td>0.759109</td>\n",
       "      <td>0.715026</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.240891</td>\n",
       "      <td>237</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.464481</td>\n",
       "      <td>0.645749</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.354251</td>\n",
       "      <td>285</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.748441</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>246</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.751012</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.248988</td>\n",
       "      <td>263</td>\n",
       "      <td>29</td>\n",
       "      <td>94</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Detector493</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.717017</td>\n",
       "      <td>0.771255</td>\n",
       "      <td>0.710900</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.228745</td>\n",
       "      <td>231</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     detector  threshold  fbeta_score  accuracy  precision    recall  \\\n",
       "0      0  Detector493      0.000     0.000000  0.591093   0.000000  0.000000   \n",
       "0      1  Detector493      0.464     0.679443  0.718623   0.838710  0.386139   \n",
       "0      2  Detector493      0.363     0.708419  0.759109   0.715026  0.683168   \n",
       "0      3  Detector493      0.252     0.464481  0.645749   0.829268  0.168317   \n",
       "0      4  Detector493      0.262     0.748441  0.789474   0.757895  0.712871   \n",
       "0      5  Detector493      0.484     0.720000  0.751012   0.788321  0.534653   \n",
       "0      6  Detector493      0.212     0.717017  0.771255   0.710900  0.742574   \n",
       "\n",
       "        mse   tn  fp   fn   tp  \n",
       "0  0.408907  292   0  202    0  \n",
       "0  0.281377  277  15  124   78  \n",
       "0  0.240891  237  55   64  138  \n",
       "0  0.354251  285   7  168   34  \n",
       "0  0.210526  246  46   58  144  \n",
       "0  0.248988  263  29   94  108  \n",
       "0  0.228745  231  61   52  150  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_real"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
