{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../artitect/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from itertools import repeat\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from artifact import Saw\n",
    "from sliding_window_detector import SlidingWindowTransformerDetector, ConvolutionalSlidingWindowDetector, SlidingWindowLinearDetector\n",
    "from mask_detector import WindowLinearDetector, WindowTransformerDetector, ConvolutionDetector\n",
    "\n",
    "from data import RealisticArtifactDataset, CachedArtifactDataset, TestArtifactDataset, CenteredArtifactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_width = 512\n",
    "\n",
    "test_path = Path(\"../data/test_files/test_label_CinCECGTorso512.pkl\")\n",
    "test = CachedArtifactDataset(file=test_path)\n",
    "\n",
    "val_path = Path(\"../data/val_files/val_SW_noCiECGT512.pkl\")\n",
    "val = CachedArtifactDataset(file=val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'act_fct' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fct'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "paths_SW = \"../models/SW_adaFCN_Trans.ckpt\" # SW ada 1d CNN Transformer\n",
    "SW_adaCNNTrans_detector = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/SW_adaFCN_Trans_rejectionSampling0_1.ckpt\" # SW ada 1d CNN Transformer\n",
    "SW_adaCNNTrans_detector_RS01 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/SW_adaFCN_Trans_rejectionSampling0_2.ckpt\" # SW ada 1d CNN Transformer\n",
    "SW_adaCNNTrans_detector_RS02 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "paths_SW = \"../models/SW_adaFCN_Trans_rejectionSampling0_3.ckpt\" # SW ada 1d CNN Transformer\n",
    "SW_adaCNNTrans_detector_RS03 = SlidingWindowTransformerDetector.load_from_checkpoint(paths_SW).cpu()\n",
    "\n",
    "SW_detectors = [SW_adaCNNTrans_detector.eval(), SW_adaCNNTrans_detector_RS01.eval(), SW_adaCNNTrans_detector_RS02.eval(), SW_adaCNNTrans_detector_RS03.eval()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_detector(input: torch.Tensor) -> int:   \n",
    "    input.squeeze(0)\n",
    "    prediction = 0\n",
    "\n",
    "    center = int(input.shape[1]/2)\n",
    "    # flag points with very high increment as artifact\n",
    "    # Calculate increments by subtracting the tensor shifted by one from the original tensor\n",
    "    increments = (input[0][1:] - input[0][:-1]).abs()\n",
    "    mean_increment = torch.mean(increments)\n",
    "    std_increment = torch.std(increments)\n",
    "\n",
    "    if increments[center-1] > (mean_increment + 3*std_increment):\n",
    "        prediction = 1\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Validation set for threshold calculation with fbeta score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/torch/nn/modules/conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "all_predictions_valSet = pd.DataFrame(columns=['Detector_id', 'predictions'])\n",
    "index = 0\n",
    "gt = list()\n",
    "\n",
    "for detector in SW_detectors:\n",
    "\n",
    "    preds = list()\n",
    "\n",
    "    for sample in val:\n",
    "        example = sample[\"data\"]\n",
    "        window  = detector.window\n",
    "        length  = len(example)\n",
    "\n",
    "        # add artifact to data\n",
    "        example_data = torch.tensor(example + sample[\"artifact\"])\n",
    "\n",
    "        # set detector to evaluation mode\n",
    "        detector.eval()\n",
    "        # make prediction and insert into prediction\n",
    "        prediction = detector(example_data.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        preds = preds + [prediction.numpy()]\n",
    "\n",
    "        if index == 0 :\n",
    "            gt = gt + [sample[\"label\"]]\n",
    "    \n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'Detector_id': index +1,\n",
    "        'predictions': preds\n",
    "    }])\n",
    "\n",
    "    all_predictions_valSet = pd.concat([all_predictions_valSet,new_row])\n",
    "    index = index +1\n",
    "    print(len(all_predictions_valSet))\n",
    "\n",
    "all_predictions_valSet = pd.concat([\n",
    "    all_predictions_valSet,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': 0,\n",
    "        'predictions': gt\n",
    "    }])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "gt = all_predictions_valSet.iloc[-1][\"predictions\"]\n",
    "metrics = pd.DataFrame()\n",
    "for index, row in all_predictions_valSet.iterrows():\n",
    "\n",
    "    max_fbeta = 0\n",
    "\n",
    "    for threshold in np.linspace(0,  1,  100):\n",
    "        predictions = np.where(np.array(row['predictions']) > threshold, 1, 0)\n",
    "\n",
    "        fbeta = fbeta_score(gt, predictions, average='macro', beta=0.5)\n",
    "\n",
    "        if (fbeta > max_fbeta):\n",
    "            max_fbeta = fbeta\n",
    "            best_threshold_fbeta = threshold\n",
    "\n",
    "    predictions = np.where(np.array(row['predictions']) > best_threshold_fbeta, 1, 0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(gt, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "    metric = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': f\"detector{row['Detector_id']}\",\n",
    "        'threshold': best_threshold_fbeta,\n",
    "        'fbeta_score': fbeta_score(gt, predictions, beta=0.5),\n",
    "        'accuracy': accuracy_score(gt, predictions),\n",
    "        'precision': precision_score(gt, predictions),\n",
    "        'recall': recall_score(gt, predictions),\n",
    "        'mse': mean_squared_error(gt, predictions), \n",
    "        'tn': tn,\n",
    "        'fp': fp, \n",
    "        'fn': fn, \n",
    "        'tp': tp\n",
    "    }])\n",
    "\n",
    "    metrics = pd.concat([metrics, metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = list(metrics[\"threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.343, 0.414, 0.454, 0.454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0] + thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window on Industry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_width = 512\n",
    "real_data_francois = pd.read_pickle('../data/francois_artifacts/francois_normalized_dataset.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = pd.read_pickle('../data/real/normalized_deviation_updated_TEST.pickle') \n",
    "ground_truth = pd.read_csv('../data/gt_changes_only_relabeled_200K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_detector(input: torch.Tensor) -> int:   \n",
    "    input.squeeze(0)\n",
    "    prediction = 0\n",
    "\n",
    "    center = int(input.shape[1]/2)\n",
    "    # flag points with very high increment as artifact\n",
    "    # Calculate increments by subtracting the tensor shifted by one from the original tensor\n",
    "    increments = (input[0][1:] - input[0][:-1]).abs()\n",
    "    mean_increment = torch.mean(increments)\n",
    "    std_increment = torch.std(increments)\n",
    "\n",
    "    if increments[center-1] > (mean_increment + 1*std_increment):\n",
    "        prediction = 1\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/torch/nn/modules/conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "all_predictions_real = pd.DataFrame(columns=['Detector_id', 'predictions'])\n",
    "dist = test_width // 2\n",
    "\n",
    "index = 1\n",
    "gt = list()\n",
    "preds_baseline = list()\n",
    "\n",
    "for index, row in ground_truth[:400].iterrows():\n",
    "    example_data = torch.tensor(real_data_df[0][int(row[\"position\"]-dist) : int(row[\"position\"]+dist)])\n",
    "    \n",
    "    prediction_baseline = baseline_detector(example_data.unsqueeze(0))\n",
    "    preds_baseline = preds_baseline + [prediction_baseline]\n",
    "\n",
    "    gt = gt + [row[\"gt\"]]\n",
    "\n",
    "all_predictions_real = pd.concat([\n",
    "    all_predictions_real,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': index,\n",
    "        'predictions': preds_baseline\n",
    "    }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "index = 2\n",
    "\n",
    "for detector in SW_detectors:\n",
    "\n",
    "    preds = list()\n",
    "\n",
    "    for index, row in ground_truth[:400].iterrows():\n",
    "        example_data = torch.tensor(real_data_df[0][int(row[\"position\"]-dist) : int(row[\"position\"]+dist)])\n",
    "        # make prediction and insert into prediction\n",
    "        prediction = detector(example_data.unsqueeze(0))\n",
    "\n",
    "        # update count\n",
    "        preds = preds + [prediction.numpy()] \n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        'Detector_id': index ,\n",
    "        'predictions': preds\n",
    "    }])\n",
    "\n",
    "    all_predictions_real = pd.concat([all_predictions_real,new_row], ignore_index=True)\n",
    "    index = index +1\n",
    "    print(len(all_predictions_real))\n",
    "\n",
    "\n",
    "all_predictions_real = pd.concat([\n",
    "    all_predictions_real,\n",
    "    pd.DataFrame([{\n",
    "        'Detector_id': 0,\n",
    "        'predictions': gt\n",
    "    }])\n",
    "    ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_predictions_real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_predictions_real\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(all_predictions_real\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindex,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_predictions_real' is not defined"
     ]
    }
   ],
   "source": [
    "all_predictions_real.drop(all_predictions_real.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detector_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>399</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>[0.29026586, 0.45724502, 0.20606177, 0.1667097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399</td>\n",
       "      <td>[0.43129468, 0.3768898, 0.34215453, 0.39736745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>399</td>\n",
       "      <td>[0.4509386, 0.43353567, 0.3983038, 0.4221497, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>399</td>\n",
       "      <td>[0.5060227, 0.44110414, 0.40732878, 0.4215525,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detector_id                                        predictions\n",
       "0         399  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
       "1         399  [0.29026586, 0.45724502, 0.20606177, 0.1667097...\n",
       "2         399  [0.43129468, 0.3768898, 0.34215453, 0.39736745...\n",
       "3         399  [0.4509386, 0.43353567, 0.3983038, 0.4221497, ...\n",
       "4         399  [0.5060227, 0.44110414, 0.40732878, 0.4215525,..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "best_threshold_fbeta = 0.5\n",
    "\n",
    "gt_real = ground_truth[:400][\"gt\"]\n",
    "metrics_real = pd.DataFrame()\n",
    "\n",
    "for index, row in all_predictions_real.iterrows():\n",
    "\n",
    "    predictions = np.where(np.array(row['predictions']) > thresholds[index], 1, 0)\n",
    "    indices_tp = [i for i, val in enumerate(predictions[gt_real==1] == 1) if val]\n",
    "    indices_fn = [i for i, val in enumerate(predictions[gt_real==1] == 0) if val]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(gt_real, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "    metric = pd.DataFrame([{\n",
    "        'index': index,\n",
    "        'detector': f\"Detector{row['Detector_id']}\",\n",
    "        'threshold': thresholds[index],\n",
    "        'fbeta_score': fbeta_score(gt_real, predictions, beta=0.5),\n",
    "        'accuracy': accuracy_score(gt_real, predictions),\n",
    "        'precision': precision_score(gt_real, predictions),\n",
    "        'recall': recall_score(gt_real, predictions),\n",
    "        'mse': mean_squared_error(gt_real, predictions), \n",
    "        'tn': tn,\n",
    "        'fp': fp, \n",
    "        'fn': fn, \n",
    "        'tp': tp, \n",
    "        'indices_tp': indices_tp, \n",
    "        'indices_fn': indices_fn\n",
    "    }])\n",
    "\n",
    "    metrics_real = pd.concat([metrics_real, metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>detector</th>\n",
       "      <th>threshold</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>indices_tp</th>\n",
       "      <th>indices_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Detector399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>218</td>\n",
       "      <td>8</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 9, 81]</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Detector399</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.657439</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>201</td>\n",
       "      <td>25</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>[2, 3, 6, 8, 9, 10, 12, 15, 16, 19, 20, 21, 22...</td>\n",
       "      <td>[0, 1, 4, 5, 7, 11, 13, 14, 17, 18, 25, 26, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Detector399</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.686813</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>208</td>\n",
       "      <td>18</td>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "      <td>[0, 3, 8, 12, 15, 16, 19, 20, 21, 24, 26, 29, ...</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Detector399</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.627490</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>207</td>\n",
       "      <td>19</td>\n",
       "      <td>111</td>\n",
       "      <td>63</td>\n",
       "      <td>[8, 15, 19, 20, 24, 26, 29, 30, 32, 35, 36, 42...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Detector399</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.622318</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>211</td>\n",
       "      <td>15</td>\n",
       "      <td>116</td>\n",
       "      <td>58</td>\n",
       "      <td>[0, 8, 15, 16, 19, 24, 26, 29, 30, 35, 36, 38,...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     detector  threshold  fbeta_score  accuracy  precision    recall  \\\n",
       "0      0  Detector399      0.000     0.068807    0.5525   0.272727  0.017241   \n",
       "0      1  Detector399      0.343     0.657439    0.6925   0.752475  0.436782   \n",
       "0      2  Detector399      0.414     0.686813    0.7075   0.806452  0.431034   \n",
       "0      3  Detector399      0.454     0.627490    0.6750   0.768293  0.362069   \n",
       "0      4  Detector399      0.454     0.622318    0.6725   0.794521  0.333333   \n",
       "\n",
       "      mse   tn  fp   fn  tp  \\\n",
       "0  0.4475  218   8  171   3   \n",
       "0  0.3075  201  25   98  76   \n",
       "0  0.2925  208  18   99  75   \n",
       "0  0.3250  207  19  111  63   \n",
       "0  0.3275  211  15  116  58   \n",
       "\n",
       "                                          indices_tp  \\\n",
       "0                                         [3, 9, 81]   \n",
       "0  [2, 3, 6, 8, 9, 10, 12, 15, 16, 19, 20, 21, 22...   \n",
       "0  [0, 3, 8, 12, 15, 16, 19, 20, 21, 24, 26, 29, ...   \n",
       "0  [8, 15, 19, 20, 24, 26, 29, 30, 32, 35, 36, 42...   \n",
       "0  [0, 8, 15, 16, 19, 24, 26, 29, 30, 35, 36, 38,...   \n",
       "\n",
       "                                          indices_fn  \n",
       "0  [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 1...  \n",
       "0  [0, 1, 4, 5, 7, 11, 13, 14, 17, 18, 25, 26, 27...  \n",
       "0  [1, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17, 18, ...  \n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14...  \n",
       "0  [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 1...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_FCNTrans = np.stack(all_predictions_real[\"predictions\"][7])\n",
    "gt = np.array(gt_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mask = (gt == 0)\n",
    "pos_mask = (gt == 1)\n",
    "\n",
    "negative_gt_preds = preds_FCNTrans[neg_mask]\n",
    "positive_gt_preds = preds_FCNTrans[pos_mask]\n",
    "\n",
    "negmin_index = np.argmin(negative_gt_preds)\n",
    "negmax_index = np.argmax(negative_gt_preds)\n",
    "posmin_index = np.argmin(positive_gt_preds)\n",
    "posmax_index = np.argmax(positive_gt_preds)\n",
    "\n",
    "original_negmin = np.where(neg_mask)[0][negmin_index]\n",
    "original_negmax = np.where(neg_mask)[0][negmax_index]\n",
    "original_posmin = np.where(pos_mask)[0][posmin_index]\n",
    "original_posmax = np.where(pos_mask)[0][posmax_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = original_negmin\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "example_data = torch.tensor(real_data_df[0][int(ground_truth[\"position\"][index]-dist) : int(ground_truth[\"position\"][index]+dist)])\n",
    "plt.plot(example_data, label=\"window without artifact\", linewidth=2, color='grey')\n",
    "plt.axvline(x=256, c=\"red\", linestyle='--', dashes=(4,4), label=\"center\", linewidth = 1)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.xlabel('#Time steps [a.u.]') \n",
    "plt.ylabel(\"[a.u.]\")\n",
    "plt.title(f\"gt = {gt[index]}; output = {preds_FCNTrans[index]}; prediction = {int(preds_FCNTrans[index] > 0.252)}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = original_negmax\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "example_data = torch.tensor(real_data_df[0][int(ground_truth[\"position\"][index]-dist) : int(ground_truth[\"position\"][index]+dist)])\n",
    "plt.plot(example_data, label=\"window without artifact\", linewidth=2, color='grey')\n",
    "plt.axvline(x=256, c=\"red\", linestyle='--', dashes=(4,4), label=\"center\", linewidth = 1)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.xlabel('#Time steps [a.u.]') \n",
    "plt.ylabel(\"[a.u.]\")\n",
    "plt.title(f\"gt = {gt[index]}; output = {preds_FCNTrans[index]}; prediction = {int(preds_FCNTrans[index] > 0.252)}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = original_posmin\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "example_data = torch.tensor(real_data_df[0][int(ground_truth[\"position\"][index]-dist) : int(ground_truth[\"position\"][index]+dist)])\n",
    "plt.plot(example_data, label=\"window with artifact\", linewidth=2, color='blue')\n",
    "plt.axvline(x=256, c=\"red\", linestyle='--', dashes=(4,4), label=\"position of artifact\", linewidth = 1)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.xlabel('#Time steps [a.u.]') \n",
    "plt.ylabel(\"[a.u.]\")\n",
    "plt.title(f\"gt = {gt[index]}; output = {preds_FCNTrans[index]}; prediction = {int(preds_FCNTrans[index] > 0.252)}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = original_posmax\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "example_data = torch.tensor(real_data_df[0][int(ground_truth[\"position\"][index]-dist) : int(ground_truth[\"position\"][index]+dist)])\n",
    "plt.plot(example_data, label=\"window with artifact\", linewidth=2, color='blue')\n",
    "plt.axvline(x=256, c=\"red\", linestyle='--', dashes=(4,4), label=\"position of artifact\", linewidth = 1)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.xlabel('#Time steps [a.u.]') \n",
    "plt.ylabel(\"[a.u.]\")\n",
    "plt.title(f\"gt = {int(gt[index])}; output = {preds_FCNTrans[index]}; prediction = {int(preds_FCNTrans[index] > 0.252)}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
